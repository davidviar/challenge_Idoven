{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# David Viar\n",
        "\n",
        "Los pasos que vamos a realizar son los siguientes:\n",
        "\n",
        "1. Las funciones básicas pedidas por Idoven\n",
        "\n",
        "    \n",
        "\n",
        "*   Be able to read the ECG files and corresponding annotations\n",
        "*   Show how they will work on the signal and plot the signal in appropriate manner to be read by a doctor\n",
        "\n",
        "*   Identify the heart beat of the signal, average and total heart beat in the signal\n",
        "*   Identify the complex QRS in the signal and been able to annotate on it\n",
        "\n",
        "2. Clasificar señales de ecg entre Myocardical infarction y paciente sano, desarrollando un método de clasíficación propio y tomando ventaja de las 15 derivaciones.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "0NeAWH6JmTdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMn-5PZR5Y7Z"
      },
      "outputs": [],
      "source": [
        "!wget https://physionet.org/static/published-projects/ptbdb/ptb-diagnostic-ecg-database-1.0.0.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descomprimimos el zip"
      ],
      "metadata": {
        "id": "jbMzkLwJ7OHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ptb-diagnostic-ecg-database-1.0.0.zip"
      ],
      "metadata": {
        "id": "nAHFsiAE5wqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las librerías necesarias con las que vamos a trabajar"
      ],
      "metadata": {
        "id": "3haRsl2_9Mak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de probar con pandas y numpy varias formas de leer los archivos, me dí cuenta que se planteaba dificil. Decidí (como se debería haber hecho desde el principio) leer la guia de la base de datos. Después de saltar por varias webs encontre el modulo wfdb."
      ],
      "metadata": {
        "id": "j7I8-nQ5NKGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb"
      ],
      "metadata": {
        "id": "IMQF7HnQakFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as ps\n",
        "\n",
        "import wfdb\n",
        "from wfdb import processing,plot\n"
      ],
      "metadata": {
        "id": "PN-XOAUP7lGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Leer, anotar y crear gráficas"
      ],
      "metadata": {
        "id": "ZMv3PGbopSfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "record = wfdb.rdrecord(\"ptb-diagnostic-ecg-database-1.0.0/patient001/s0010_re\")"
      ],
      "metadata": {
        "id": "aZNej4m59QCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el comando para obtener la señal almacenada en el objeto record"
      ],
      "metadata": {
        "id": "qAxYePbQEHLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = record.p_signal.T"
      ],
      "metadata": {
        "id": "LoVyBzBBKPST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el comando sig_name para obtener los nombres de las señales almacenadas en el objeto record"
      ],
      "metadata": {
        "id": "Ow6jmfEUEPJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = record.sig_name"
      ],
      "metadata": {
        "id": "vw6ePFkPEAb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El atributo fs nos da información de la frecuencia de muestreo de la señal"
      ],
      "metadata": {
        "id": "UHRSir2tEaiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq = record.fs"
      ],
      "metadata": {
        "id": "6_B6Qp2aEXKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos las unidades de las señales."
      ],
      "metadata": {
        "id": "41On7SB3Eg2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unit = record.units"
      ],
      "metadata": {
        "id": "zOshyomEHxP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a jugar con la señal, antes de crear el gráfico con las funciones de wfdb. Creamos el gráfico para una única derivación, ajustando el tiempo en segundos y la intensidad en mV. A partir de este generaremos un gráfico más realista con las 15 derivaciones."
      ],
      "metadata": {
        "id": "BLvoy2HlROVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = 0 #cambiando el número podemos cambiar de derivación\n",
        "\n",
        "ps.line(y=data[num],x=np.arange(0,38400)/freq, labels={'x':'t (s)', 'y':unit[num]},title=\"Signal Name \" + name[num])"
      ],
      "metadata": {
        "id": "d1prhqLvOar6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wfdb.plot_wfdb(record,title=\"prueba\",figsize=(40,30),ecg_grids=\"all\")"
      ],
      "metadata": {
        "id": "-cq4JIi2GSBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos que la función para generar electrocardiogramas funciona correctamente. Vemos varias partes a mejorar si un especialista quisiera darle  un uso convencional al programa: no es necesario obtener todo el rango de la señal y las últimas derivaciones no suelen usarse tanto si queremos obtener información básica. A modo de práctica vamos a coger una ventana dentro del electro y eliminar las tres últimas derivaciones"
      ],
      "metadata": {
        "id": "2gDKIvi0Xnwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brief_record = wfdb.rdrecord('ptb-diagnostic-ecg-database-1.0.0/patient001/s0010_re',sampfrom=1000, sampto=6000,channel_names=['i',\n",
        " 'ii',\n",
        " 'iii',\n",
        " 'avr',\n",
        " 'avl',\n",
        " 'avf',\n",
        " 'v1',\n",
        " 'v2',\n",
        " 'v3',\n",
        " 'v4',\n",
        " 'v5',\n",
        " 'v6'])\n",
        "\n",
        "brief_annotation = wfdb.rdann('ptb-diagnostic-ecg-database-1.0.0/patient001/s0010_re', 'xyz',sampfrom=1000 ,sampto=6000)"
      ],
      "metadata": {
        "id": "OwEqC5n9X-K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wfdb.plot_wfdb(record=brief_record, annotation=brief_annotation, plot_sym=True,\n",
        "                   time_units='seconds', title='MIT-BIH Record 100',\n",
        "                   figsize=(40,30), ecg_grids='all')"
      ],
      "metadata": {
        "id": "3z81GLsWY_Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos detectar y medir la frecuencia cardiaca, hay variaos algoritmos publicados, muchos de ellos ya integrados en librerias  de programación para facilitar su uso. Yo he didido usar GQRS dentro de wfdb."
      ],
      "metadata": {
        "id": "ZBkaSjuHauRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "record_2 = wfdb.rdrecord('ptb-diagnostic-ecg-database-1.0.0/patient001/s0010_re', channels=[0], physical=False)\n",
        "\n",
        "qrs_locs_2 = processing.gqrs_detect(d_sig=record_2.d_signal[:,0],\n",
        "                                        fs=record_2.fs,\n",
        "                                        adc_gain=record_2.adc_gain[0],\n",
        "                                        adc_zero=record_2.adc_zero[0])"
      ],
      "metadata": {
        "id": "UvWCyZfRicym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez calculado el complejo QRS, es facil detectar la frecuencia cardiaca, debemos calcular el tiempo entre complejos. Aunque hay una función dedicada, la parte teórica sería saber cuanto tiempo ha pasado entre un complejo y otro (Q(t)-Q(t-1)) lo mismo para R o S."
      ],
      "metadata": {
        "id": "I4dMcB5fcZOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intervals = processing.calc_rr(qrs_locs_2, fs=record_2.fs)\n",
        "print(intervals)\n"
      ],
      "metadata": {
        "id": "_f3rzXemigeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez calculados los intervalos entre complejos, lanzamos la función para calcular el ritmo cardiaco medio dentro del electro."
      ],
      "metadata": {
        "id": "oPw6rDlMc6dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hrm= processing.calc_mean_hr(intervals,fs=record_2.fs)\n",
        "\n",
        "print(\"El ritmo cardiaco medio es de {} pulsaciones por minuto\".format(hrm))"
      ],
      "metadata": {
        "id": "1PGwGuSTc685"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conociendo el complejo QRS es muy facil calcular cualquier otra propiedad relacionada con el ritmo cardiaco. En el siguiente ejemplo calculamos el ritmo cardiaco entre cada complejo."
      ],
      "metadata": {
        "id": "m7pwGEeegD-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wfdb.processing.compute_hr(record_2.sig_len, qrs_locs_2, fs=record_2.fs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A57iR_sHbOsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez conseguido el complejo qrs podemos guardarlo como anotación o bien crear una gráfica fusionando señal y anotación."
      ],
      "metadata": {
        "id": "Ush19UrUtftY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processing.rr2ann(intervals,\"ptb-diagnostic-ecg-database-1.0.0/patient001/anotation_rr_test\",\"atr\",record_2.fs)"
      ],
      "metadata": {
        "id": "uGlt-MyKhq6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrar las anotaciones sobre el gráfico también es una buena práctica para comprobar que ha funcionado el algoritmo de detección de complejo QRS"
      ],
      "metadata": {
        "id": "ujq5USlMtxzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot.plot_items(record_2.d_signal/record_2.fs,[qrs_locs_2],figsize=(40,10),sig_units=record_2.units,ecg_grids=[0],fs=record_2.fs,time_units=\"seconds\")"
      ],
      "metadata": {
        "id": "giBa_e0Wl4ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo que hay un fallo en la función anterior que no utiliza correctamente las unidades propuestas, provocando que aparezcan infinitas líneas (grid) en la gráfica. Para solucionarlo he divido la señal por 1000 para transformarla en mV, obteniendo un resultado positivo."
      ],
      "metadata": {
        "id": "KULDgZdtvN9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Parte de desarrollo libre.\n",
        "Teniendo en cuenta que cada paciente cuenta con un electro de 15 derivaciones, se puede sacar partido  de esto y plantearlo como información 2D. Al final una señal 2D no deja de ser (en cierta medida) parecido a una imagen, por lo que podemos aplicar algoritmos de deep learning para resolver nuestro problema.\n",
        "\n",
        "El objetivo es montar una red de clasificación que puede detectar de forma precisa entre pacientes con Myocardial infarction y pacientes sanos. La red que voy a implementar es muy simple para demostrar que es posible tratar una señal de ecg como una imagen. Esto se podria mejorar mucho más aplicando convoluciones y otro tipo de arquitecturas."
      ],
      "metadata": {
        "id": "0lszZ4TWpdxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import os "
      ],
      "metadata": {
        "id": "mGCCBJFwx4Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OCjjFco5XFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genero la base de datos, leyendo la información de cada paciente y guardando su ecg en una carpeta nombrada con la patología. "
      ],
      "metadata": {
        "id": "oJ4CAfhWqR6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "root = \"ptb-diagnostic-ecg-database-1.0.0\"\n",
        "paths = glob.glob(root+\"/patient*/*dat\")\n",
        "for path in paths:\n",
        "  path_splited = path.split(\"/\")\n",
        "  patient_num = path_splited[1]\n",
        "  file_name = path_splited[2]\n",
        "  record = wfdb.rdrecord(path.split(\".dat\")[0])\n",
        "  reason_admission = record.comments[4].split(\"Reason for admission: \")[1]\n",
        "  if not os.path.exists(reason_admission):\n",
        "    os.makedirs(reason_admission) \n",
        "  else:\n",
        "    np.save(reason_admission+\"/\"+patient_num+\"_\"+file_name.split(\".\")[0]+\".npy\",record.p_signal.T[:,:32000])"
      ],
      "metadata": {
        "id": "81KMz6_4Apmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signals=[]\n",
        "\n",
        "for file in os.listdir(\"Myocardial infarction/\"):\n",
        "  signals.append(np.load(\"Myocardial infarction/\"+file))\n",
        "\n",
        "labels_infarction=np.ones(len(signals))\n",
        "\n",
        "for file in os.listdir(\"Healthy control/\"):\n",
        "  signals.append(np.load(\"Healthy control/\"+file))\n",
        "\n",
        "labels_controls=np.ones(len(signals)-labels_infarction.shape[0])*0\n",
        "\n",
        "labels = np.append(labels_infarction,labels_controls)\n",
        "signals = np.dstack(signals)\n",
        "signals = np.rollaxis(signals,-1)\n",
        "print(signals.shape,labels.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((signals, labels))\n",
        "\n"
      ],
      "metadata": {
        "id": "x9-Mj2rWa4wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.save()"
      ],
      "metadata": {
        "id": "EeLAAJLDQJ9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((signals, labels))\n"
      ],
      "metadata": {
        "id": "F1ki_SiXywWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora devemos tomar una parte para validation, train y test. Para ello utilizo una función ya implementada en tf"
      ],
      "metadata": {
        "id": "If4gaN4rr6sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    if shuffle:\n",
        "        # Specify seed to always have the same split distribution between runs\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "jyylW724sD3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aleatorizo el dataset y creo el batch de entrenamiento"
      ],
      "metadata": {
        "id": "ZyrdKV-GqoS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " train_ds, val_ds, test_ds=get_dataset_partitions_tf(train_dataset,labels.shape[0])"
      ],
      "metadata": {
        "id": "S15e9zYZsHDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "val_ds = val_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "uiAGjc7ugr2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "_7voklyG5ZLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con las siguientes líneas de código almacenamos memoria en cache para ahorrar espacio en ram.\n",
        "\n"
      ],
      "metadata": {
        "id": "E7FG0rjSuGrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "mBBkpq5RYms4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "test_ds = test_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "iE752-hg6hsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds, val_ds,test_ds)"
      ],
      "metadata": {
        "id": "A9dhP7SVwKOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genero una red densamente conexa muy sencilla para clasificar"
      ],
      "metadata": {
        "id": "k1wZo1Muq3Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(15, 32000)),\n",
        "   \n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "n-hHhbVyEvxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wBGMGeTdtcom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos la red con el dataset generado"
      ],
      "metadata": {
        "id": "0H101u5sq5UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,validation_data=val_ds, batch_size=30, epochs=20)"
      ],
      "metadata": {
        "id": "kw9IeIcdFJ7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)\n"
      ],
      "metadata": {
        "id": "Bbc9BSBUu6rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Los resultados finales para el conjunto de test (46 ecgs) son un 91.30% de accuracy y una perdida de 7.54."
      ],
      "metadata": {
        "id": "3kUA31Gf9KN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos resultados se pueden mejorar en gran medida aplicando redes convolucionales e incluso añadiendo capas densas a la arquictura original.\n",
        "\n",
        "Esto demuestra que los algoritmos de Deep Learning pueden ser usados en clasificación de ecg.\n"
      ],
      "metadata": {
        "id": "1iW8AFc99sNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuación ejercicio libre aplicando CNN\n",
        "\n",
        "Siguiendo con las líneas futuras planteadas anteriormente, diseñamos una arquitectura CNN. \n",
        "\n",
        "Creamos una capa específica RESNET (https://arxiv.org/abs/1512.03385v1) que potencia el gradiente. Mantenemos los parámetros de entrenamiento. Aplicando convoluciones hemos reducido el número de parámetros de la red de 61 millones a 7 millones."
      ],
      "metadata": {
        "id": "osQ4s4Wjqsdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetIdentityBlock(tf.keras.Model):\n",
        "  def __init__(self, kernel_size, filters,name):\n",
        "    super(ResnetIdentityBlock, self).__init__(name=name)\n",
        "    filters1, filters2, filters3 = filters\n",
        "    \n",
        "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
        "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
        "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
        "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.conv2a(input_tensor)\n",
        "    x = self.bn2a(x, training=training)\n",
        "    y = tf.nn.relu(x)\n",
        "\n",
        "    x = self.conv2b(y)\n",
        "    x = self.bn2b(x, training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "\n",
        "    x = self.conv2c(x)\n",
        "    x = self.bn2c(x, training=training)\n",
        "\n",
        "    x += y\n",
        "    return tf.nn.relu(x)\n"
      ],
      "metadata": {
        "id": "F4cg7ArsCxnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.keras.Input((15, 32000,1))\n",
        "\n",
        "c1 = ResnetIdentityBlock(filters=[16,16,16],kernel_size=(3,3),name=\"resent1\")(input)\n",
        "\n",
        "m1 = tf.keras.layers.MaxPool2D((1,5))(c1)\n",
        "\n",
        "c2 =  ResnetIdentityBlock(filters=[32,32,32],kernel_size=(3,3),name=\"resent2\")(m1)\n",
        "\n",
        "m2 = tf.keras.layers.MaxPool2D((1,5))(c2)\n",
        "\n",
        "c3 =  ResnetIdentityBlock(filters=[32,32,32],kernel_size=(3,3),name=\"resent3\")(m2)\n",
        "\n",
        "m3 = tf.keras.layers.MaxPool2D((1,5))(c3)\n",
        "f1= tf.keras.layers.Flatten()(m3)\n",
        "d1 = tf.keras.layers.Dense(64, activation='relu')(f1)\n",
        "\n",
        "d2= tf.keras.layers.Dense(1,activation=\"sigmoid\")(d1)\n",
        "model=tf.keras.Model(input,d2)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "33wr27iARad8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "MTRwG2Gzv0l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos la red con el dataset generado"
      ],
      "metadata": {
        "id": "LBknklXyv0l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,validation_data=val_ds, batch_size=30, epochs=20)"
      ],
      "metadata": {
        "id": "FLpJTUwKv0mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos conseguido mejorar los resultados de la red, no solo mejorando el accuracy sino también hemos reducido el loss un orden de magnitud."
      ],
      "metadata": {
        "id": "Pynnq1GLsgFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)\n"
      ],
      "metadata": {
        "id": "YuNOeukZv0mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTANTE: Para llevar a cabo buenas prácticas se debería de realizar un cross-validation para cada uno de los entrenamientos."
      ],
      "metadata": {
        "id": "MwL-Gx0nsqoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Cómo pienso que se podría mejorar?\n",
        "\n",
        "El ejemplo anterior es solo una idea de lo que podría ofrecer a Idoven como Data Scientist. A continuación, propongo mejoras que podrían hacerse al problema de clasificación. \n",
        "\n",
        "Añado que al igual que hemos clasificado entre pacientes sanos y con Myocardial infarction, también se podrían añadir el resto de clases por las que un paciente es ingresado (Palpitation, Myocarditis...)."
      ],
      "metadata": {
        "id": "fjEs5Ehx-CJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El bonito mundo de las convoluciones. Se ha demostrado en varios artículos que en muchos casos (donde hay información espacial sobre todo) mejoran al comportamiento de las redes densas (el ejemplo anterior) y necesitan menor computo.\n",
        "\n",
        "Teniendo esto en cuenta es dificil aplicar convoluciones a un ecg de la forma que se presentaba anterior mente (una matriz de 15X32000). Para concentrar la información podemos usar un espectrograma que através de diferentes  transformaciones en frecuencia con la señal, se obtine una imagen."
      ],
      "metadata": {
        "id": "Su8Fo8-b-2TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,a=scipy.signal.spectrogram(record_2.d_signal.T,fs=record_2.fs)"
      ],
      "metadata": {
        "id": "SLQnOQwyx6f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "ax.imshow(a[0][::-1,:])\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "tEyTQT3i4ugS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez obtenida esta imagen, podemos aplicar un logaritmo para potenciar las partes con información. De igual manera, una vez concentrada la información podemos aplicar convoluciones 2D y volver a montar una red de clasificación, añadiendo si quisieramos el resto de etiquetas."
      ],
      "metadata": {
        "id": "ADr3Qcuy_d7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "ax.imshow(np.log(a[0])[::-1,:])\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "FnsY5f_Qzn57"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}